usersimcrs.simulator.llm.llm_dual_prompt_user_simulator
=======================================================

.. py:module:: usersimcrs.simulator.llm.llm_dual_prompt_user_simulator

.. autoapi-nested-parse::

   User simulator leveraging a large language model to generate responses.

   The generation of responses is based on two prompts. The first one establishes
   if the conversation should continue or not. The second one is used to generate
   the user response.



Classes
-------

.. autoapisummary::

   usersimcrs.simulator.llm.llm_dual_prompt_user_simulator.LLMDualPromptUserSimulator


Module Contents
---------------

.. py:class:: LLMDualPromptUserSimulator(id: str, domain: usersimcrs.core.simulation_domain.SimulationDomain, item_collection: usersimcrs.items.item_collection.ItemCollection, llm_interface: usersimcrs.llm_interfaces.llm_interface.LLMInterface, item_type: str, task_definition: str = DEFAULT_TASK_DEFINITION, stop_definition: str = DEFAULT_STOP_DEFINITION, persona: usersimcrs.user_modeling.persona.Persona = None)

   Bases: :py:obj:`usersimcrs.simulator.user_simulator.UserSimulator`


   Initializes the user simulator.

   :param id: User simulator ID.
   :param llm_interface: Interface to the large language model.
   :param item_type: Type of the item to be recommended. Defaults to None.
   :param task_definition: Definition of the task to be performed.
                           Defaults to DEFAULT_TASK_DEFINITION.
   :param stop_definition: Definition of the stop task. Defaults to
                           DEFAULT_STOP_DEFINITION.
   :param persona: Persona of the user. Defaults to None.


   .. py:attribute:: llm_interface


   .. py:attribute:: generation_prompt


   .. py:attribute:: stop_prompt


